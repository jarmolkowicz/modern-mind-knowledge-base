---
status: emerging
area: [erosion]
sources:
  - "Nosta (2025)"
reviewed_by:
reviewed_date:
---

# Coherence Trap

## What It Is

The tendency to accept information as true when it flows smoothly and aligns with existing beliefs, regardless of factual accuracy. AI amplifies this trap because LLMs produce exceptionally coherent language—text that feels right even when it's wrong.

## Why It Matters

"Coherence isn't a marker of accuracy, it's a marker of ease." (Nosta, 2025)

LLMs don't understand truth—they predict statistically plausible word sequences. Humans evaluate AI outputs using the same flawed coherence metric that generated them. This creates a feedback loop: "LLM coherence feels like comprehension, and our brains go along for the ride."

## The Loop of Plausibility

When algorithmic fluency meets human emotion:
1. AI generates coherent text
2. Human brain experiences ease of processing
3. Ease feels like truth ([[fluency-bias]])
4. Human accepts conclusion without verification
5. Reinforces trust in coherent AI output

This explains why misinformation and polished marketing prove effective—coherence creates emotional conviction.

## Key Quote

"We aren't losing our minds to machines. We are...learning to think like them."

## Solution

Embrace cognitive friction: "patience, context, and doubt" as distinctly human safeguards. Deliberately tolerate discomfort and uncertainty.

## Relationship to Fluency Bias

The coherence trap extends [[fluency-bias]] into epistemological territory:
- Fluency bias: easy to process → feels true
- Coherence trap: internally consistent → feels proven

## Related

- [[fluency-bias]] - underlying mechanism
- [[automation-bias]] - accepting AI conclusions uncritically
- [[metacognition]] - doubt as protective factor
- [[calibration]] - maintaining accurate self-assessment
