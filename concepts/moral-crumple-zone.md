---
status: emerging
area: [risk]
sources:
  - "Hohenstein & Jung (2020)"
reviewed_by:
reviewed_date:
---

# Moral Crumple Zone

## What It Is

When AI mediates communication and things go wrong, the AI absorbs blame like a crumple zone in a car crash—reducing responsibility attributed to the human communicator.

## Why It Matters

AI changes accountability dynamics. When failure can be attributed to the AI, humans may take less care with communication. This could prevent authentic relationship repair and learning from mistakes.

## Key Insight

From experimental research:
- Successful AI-mediated communication actually *increased* trust (4.8 → 5.76 out of 6)
- When communication failed, AI was blamed more than human partners
- AI perceived as "coercive agent" only when things went wrong

## The Asymmetry

**Success**: AI is invisible/instrumental, humans get credit
**Failure**: AI becomes an agent that absorbs blame

## Implications

**For communication**:
- People may use AI partly to protect themselves from blame
- Careless communication may increase if consequences are buffered

**For relationships**:
- Short-term protection from discomfort
- Long-term prevention of authentic repair
- The buffer that protects also isolates

## Related

- [[transparency-paradox]] - when AI involvement is known
- [[affective-trust-deficit]] - what's lost in AI mediation
- [[accountability]] - what shifts
