---
status: solid
area: [preservation]
sources:
  - "Passalacqua et al. (2024)"
  - "Scispace Literature Synthesis (2025)"
reviewed_by:
reviewed_date:
---

# Partial Automation Principle

## What It Is

Partial automation preserves skills AND motivation better than full automation. Keeping humans engaged in part of the process—rather than automating everything—produces better long-term outcomes.

## Why It Matters

This is the strongest evidence-based principle for AI collaboration design. With a large effect size (d = 0.9), it provides confident guidance: don't automate completely even when you can.

## Key Insight

From 831-paper literature synthesis:
- Full automation → 23% worse skill acquisition vs. partial automation
- Mechanism: Partial automation maintains autonomy, cognitive engagement, and practice opportunities
- Reduced autonomy → lower motivation → less engagement → skill deficit

## The Chain

```
Full automation
    ↓
Reduced autonomy
    ↓
Lower self-determined motivation
    ↓
Less cognitive engagement
    ↓
Skill deficit over time
```

## Design Implication

When designing AI workflows:
- Keep humans involved in meaningful parts of the process
- Don't optimize purely for efficiency
- Preserve opportunities for practice and judgment
- Human-in-the-loop is not just for safety—it's for capability

## Evidence Quality

This is among the strongest findings in AI-human collaboration research. Multiple studies converge on the same conclusion with large effect sizes.

## Related

- [[strategic-alternation]] - how to implement this
- [[cognitive-debt]] - what full automation accumulates
- [[desirable-difficulty]] - why engagement matters
- [[think-first]] - practice that applies this
