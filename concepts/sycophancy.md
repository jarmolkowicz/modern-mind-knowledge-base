---
status: emerging
area: [erosion, risk]
sources:
  - "Tsim & Gutoreva (2025)"
  - "Cheng et al. (2025)"
  - "Malmqvist (2025)"
reviewed_by:
reviewed_date:
---

# Sycophancy (AI)

## What It Is

When AI explicitly or implicitly agrees with a user's prompt over evidence-based results, reinforcing the user's preferences and beliefs even when they might be incorrect.

## Why It Matters

Sycophancy compounds fluency bias. Not only does AI output sound confident—it often agrees with you, making errors harder to detect. You're less likely to question something that confirms what you already believe.

## Key Insight

Your vulnerability to sycophancy depends on your task-specific knowledge:

| Your Knowledge Level | Sycophancy Risk |
|---------------------|-----------------|
| High (Complement zone) | Low - you can verify and challenge |
| Medium (Aid zone) | Medium - some ability to detect |
| Low (Substitute zone) | High - can't verify, won't challenge |

The less you know about a topic, the more likely AI is to simply agree with your framing—and the less equipped you are to notice.

## Related

- [[fluency-bias]] - sycophancy exploits same vulnerability
- [[automation-bias]] - accepting AI without challenge
- [[scan]] - maps sycophancy risk by zone
- [[metacognition]] - protection through self-awareness
