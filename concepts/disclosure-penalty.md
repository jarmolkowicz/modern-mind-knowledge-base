---
status: solid
area: [risk]
sources:
  - "Reimann & Schilke (2025)"
  - "Cheong et al. (2025)"
reviewed_by:
reviewed_date:
---

# Disclosure Penalty

## What It Is

The measurable reduction in trust, perceived competence, and credibility that occurs when someone reveals they used AI assistance—regardless of actual output quality.

## Why It Matters

Creates a concrete professional cost for transparency. When disclosure carries a 16-20% trust penalty, professionals face real career and relationship consequences for honesty about AI use.

## Key Insight

The penalty is remarkably consistent across contexts and resistant to mitigation:

| Context | Trust Reduction |
|---------|----------------|
| Professors (grading) | -16% |
| Firms (advertising) | -18% |
| Designers (creative work) | -20% |
| Engineers (coding) | -9% competence |

Soft disclosure language ("AI only helped with grammar," "human reviewed") does not reduce the penalty.

## Demographic Disparity

Penalties are unequally distributed:
- Female engineers: -13% competence rating
- Male engineers: -6% competence rating
- Result: Women adopt AI at lower rates (31% vs 41%)

## Worse Than Disclosure

Getting caught using AI without disclosing produces even larger trust drops than voluntary disclosure—creating perverse incentives to hide and hope.

## Related

- [[transparency-paradox]] - the broader pattern
- [[stigma-management]] - how people navigate this
- [[authenticity]] - what's at stake
