---
status: solid
area: [preservation]
sources:
  - "Tankelevitch et al. (2024)"
reviewed_by:
reviewed_date:
---

# Metacognitive Demand

## What It Is

AI systems require users to constantly monitor (assess quality) and control (adjust strategy) their interactions. This metacognitive load is substantial and most users are not equipped to handle it.

## Why It Matters

Using AI effectively isn't about tool mastery—it's about metacognitive skill. Without strong monitoring and control, you can't distinguish good AI outputs from bad ones or calibrate when to trust versus override.

## Key Insight

Every AI interaction requires:

**Monitoring**: Is this output accurate? Appropriate? High quality? Am I understanding it correctly?

**Control**: Should I accept, edit, regenerate, or abandon? Should I change my prompt? Should I do this myself?

Most users default to low-engagement approaches—accepting outputs with minimal evaluation.

## Three Demand Areas

1. **Prompting**: Do I understand what this AI can do? Is my prompt clear?
2. **Evaluating**: Is this accurate? How do I know?
3. **Automation Strategy**: Which tasks should I delegate? Where are the boundaries?

## The Processing Fluency Problem

AI outputs are grammatically correct, well-formatted, confident in tone. This smoothness creates "processing fluency"—ease of reading signals truth. Users conflate "sounds good" with "is correct."

## Broken Feedback Loops

Traditional learning: Make decision → see outcome → adjust strategy

With AI: Accept output → rarely see if correct → no calibration

Metacognitive accuracy doesn't improve with AI experience because feedback is missing.

## Related

- [[calibration]] - the skill this describes
- [[fluency-bias]] - why evaluation is hard
- [[jagged-frontier]] - what you're trying to navigate
