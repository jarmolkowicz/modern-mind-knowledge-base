---
status: emerging
area: [erosion, risk]
sources:
  - "Nosta (2025)"
  - "Jarmołkowicz (2025)"
reviewed_by:
reviewed_date:
---

# Capacity Erosion

## What It Is

The gradual degradation of cognitive capabilities through disuse, particularly when AI handles tasks that previously exercised those capabilities.

## Why It Matters

Erosion is gradual and invisible. AI output quality stays high, so you don't notice your own contribution shrinking. By the time erosion becomes apparent, recovery is much harder than prevention.

## Key Insight

Three illusions hide erosion:
- **Fluency illusion**: AI's polished output feels like your understanding
- **Competence illusion**: Borrowed capability feels like yours
- **Productivity illusion**: More output feels like growth

You cannot trust how you feel about your AI use. Focus on observable behaviors: Can you work without AI? Do you catch errors? Do you transform AI output significantly?

## AI Rebound Effect

Research cited by Nosta (2025): When gastroenterologists stopped using AI for polyp detection, their performance dropped **below their pre-AI baseline**—not just to where they started. This "AI rebound" suggests AI's performance boost comes at the cost of degraded underlying capabilities. Erosion isn't just skill pause—it's active degradation.

## Related

- [[cognitive-offloading]] - the behavior that causes erosion
- [[fluency-bias]] - helps mask erosion
- [[strategic-alternation]] - the counter-strategy
- [[green-yellow-red-monitoring]] - detects erosion early
- [[ai-oscillation-trap]] - switching-specific erosion
- [[borrowed-certainty]] - confidence without ownership
