---
status: solid
area: [risk]
type: paper
sources:
  - "Cheong, I., et al. (2025). Penalizing Transparency? How AI Disclosure and Author Demographics Shape Human and AI Judgments About Writing. arXiv:2507.01418v1."
reviewed_by:
reviewed_date:
---

# Cheong et al. (2025) - Penalizing Transparency

## Citation

Cheong, I., Guo, A., Lee, M., Liao, Z., Kadoma, K., Go, D., Chang, J.C., Henderson, P., Naaman, M., & Zhang, A.X. (2025). Penalizing Transparency? How AI Disclosure and Author Demographics Shape Human and AI Judgments About Writing. *arXiv:2507.01418v1*.

**URL:** [arXiv](https://arxiv.org/html/2507.01418v1)

## Type

Paper (empirical research)

## Key Insight

AI disclosure penalties exist across demographic groups, but LLM evaluators showed "vanishing alignment"—fairness-oriented preferences disappeared when AI assistance was revealed. This suggests transparency burdens may fall asymmetrically on marginalized groups.

## Methodology

- 1,970 human raters evaluated identical news articles
- 2×3×3 factorial design (AI disclosure × race × gender)
- 2,520 LLM assessments for comparison

## Relevance

Demonstrates that AI disclosure creates measurable bias in both human and AI evaluation, with potential equity implications.

## Supports

- [[transparency-paradox]] - documents the penalty
- [[disclosure-penalty]] - quantifies the effect
