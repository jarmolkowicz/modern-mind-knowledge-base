---
status: solid
area: [preservation]
type: paper
sources:
  - "Tankelevitch, L., et al. (2024). The Metacognitive Demands and Opportunities of Generative AI. CHI 2024."
reviewed_by:
reviewed_date:
---

# Tankelevitch et al. (2024) - Metacognitive Demands

## Citation

Tankelevitch, L., Kewenig, V., Simkute, A., Scott, A.E., Sarkar, A., Sellen, A., & Rintel, S. (2024). The Metacognitive Demands and Opportunities of Generative AI. *CHI '24: Proceedings of the CHI Conference on Human Factors in Computing Systems*.

**DOI:** [10.1145/3613904.3642902](https://dl.acm.org/doi/10.1145/3613904.3642902)

## Type

Paper (HCI research)

## Key Insight

AI systems impose high metacognitive demandsâ€”constant monitoring (Is this good?) and control (What should I do?). Most users lack these skills and default to blind trust. Processing fluency (smooth AI output) creates false confidence.

## Key Findings

Three demand areas:
1. Prompting: Understanding AI capabilities
2. Evaluating: Assessing output quality
3. Automation strategy: Knowing when to delegate

Feedback loops are broken: users rarely discover if AI outputs were correct, preventing calibration.

## Relevance

Provides theoretical framework for why [[calibration]] is essential and why using AI well is a skill distinct from tool proficiency.

## Supports

- [[metacognitive-demand]] - primary source
- [[calibration]] - validates importance
- [[fluency-bias]] - explains mechanism
