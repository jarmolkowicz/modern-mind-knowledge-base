---
status: solid
area: [preservation, risk]
type: paper
sources:
  - "Tankelevitch, L., et al. (2023). The Metacognitive Demands of Generative AI. arXiv."
reviewed_by:
reviewed_date:
---

# Tankelevitch et al. (2023) - Metacognitive Demands of Generative AI

## Citation

Tankelevitch, L., Kewenig, V., Simkute, A., Scott, A. E., Sarkar, A., Sellen, A., & Rintel, S. (2024). The Metacognitive Demands and Opportunities of Generative AI. *CHI '24: Proceedings of the CHI Conference on Human Factors in Computing Systems*. (Best Paper Award)

**arXiv:** [2312.10893](https://arxiv.org/abs/2312.10893)
**DOI:** [10.1145/3613904.3642902](https://doi.org/10.1145/3613904.3642902)

## Type

Paper (theoretical/empirical)

## Key Insight

Generative AI creates novel metacognitive demands: users must evaluate AI output without the learning that typically produces evaluation skill. AI shifts the cognitive task from production to evaluation, but evaluation without production experience is unreliable.

## Relevance

Directly addresses the core Modern Mind problem: AI output requires judgment you may not have if you didn't build the skill yourself. Explains why even "just evaluating" AI output requires maintained capacity.

## Supports

- [[metacognition]] - AI-specific demands
- [[capacity-erosion]] - why evaluation skill degrades
- [[calibration]] - difficulty of calibrating AI trust
