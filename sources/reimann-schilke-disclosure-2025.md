---
status: solid
area: [risk]
type: paper
sources:
  - "Reimann, M., & Schilke, O. (2025). Disclosing AI Use Can Backfire. University of Arizona."
reviewed_by:
reviewed_date:
---

# Reimann & Schilke (2025) - Disclosure Backfires

## Citation

Reimann, M., & Schilke, O. (2025). Disclosing AI Use Can Backfire. University of Arizona, Eller College of Management.

**URL:** [University of Arizona News](https://news.arizona.edu/news/disclosing-ai-use-can-backfire-research-shows)

## Type

Paper (empirical research)

## Key Insight

Across 13 experiments with 5,000+ participants, AI disclosure consistently reduced trust by 16-20%. Soft disclosure language ("only used for grammar," "human reviewed") did not mitigate the effect. Getting caught is worse than disclosing voluntarily.

## Key Findings

| Context | Trust Reduction |
|---------|----------------|
| Professors (grading) | -16% |
| Firms (advertising) | -18% |
| Designers (creative) | -20% |

## Relevance

Strongest empirical evidence for [[disclosure-penalty]]. Establishes that transparency has measurable professional costs regardless of context or mitigation attempts.

## Supports

- [[transparency-paradox]] - core evidence
- [[disclosure-penalty]] - primary source
