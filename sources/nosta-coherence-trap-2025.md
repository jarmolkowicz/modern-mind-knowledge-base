---
status: emerging
area: [erosion]
type: article
sources:
  - "Nosta, J. (2025). The Coherence Trap: How AI Is Teaching Us to Feel Truth. Psychology Today."
reviewed_by:
reviewed_date:
---

# Nosta (2025) - Coherence Trap

## Citation

Nosta, J. (2025, October). The Coherence Trap: How AI Is Teaching Us to Feel Truth. *Psychology Today*.

**URL:** [psychologytoday.com](https://www.psychologytoday.com/us/blog/the-digital-self/202510/the-coherence-trap-how-ai-is-teaching-us-to-feel-truth)

## Type

Article (thought leadership)

## Key Insight

Truth is increasingly determined by emotional coherence rather than factual accuracy. When information flows smoothly and aligns with existing beliefs, we emotionally accept it as true regardless of factual basis. "Coherence isn't a marker of accuracy, it's a marker of ease."

## The Loop of Plausibility

LLMs don't understand truthâ€”they predict statistically plausible word sequences. Humans evaluate AI outputs using the same flawed coherence metric that generated them. This creates a feedback loop: "LLM coherence feels like comprehension, and our brains go along for the ride."

## Key Quote

"We aren't losing our minds to machines. We are...learning to think like them."

## Solution

Embrace cognitive friction: "patience, context, and doubt" as distinctly human safeguards. Deliberately tolerate discomfort and uncertainty.

## Relevance

Extends [[fluency-bias]] into epistemological territory. Explains why misinformation and AI-generated content feels convincing even when false.

## Supports

- [[coherence-trap]] - defines the concept
- [[fluency-bias]] - extends with truth-feeling mechanism
- [[metacognition]] - doubt as protective factor
